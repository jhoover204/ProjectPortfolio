{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JRH_Build_Neural_Train_Sets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Dissertation/Space Intelligence/')\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIKLtCyP1CF",
        "outputId": "d3c1c370-c53f-4f7e-94c6-5400082cdf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " checkpoints\n",
            "'Copy of cyclegan.ipynb'\n",
            "'Copy of pix2pix.ipynb'\n",
            " Data\n",
            " Exploratory_Data_Analysis_and_Linear_Models.ipynb\n",
            "'Filling the GAPS S-CycleGAN_Attempt.ipynb'\n",
            " JRH_Filling_the_GAPS_Build_Training_Sets.ipynb\n",
            " JRH_Filling_the_Gaps_Image_Generation2.ipynb\n",
            " JRH_Filling_the_Gaps_Image_Generation.ipynb\n",
            " JRH_Filling_the_Gaps_Model_Building.ipynb\n",
            " logs\n",
            " output_images\n",
            " pix2pix_cGAN\n",
            " S-CycleGAN_Attempt.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installations\n",
        "%%capture\n",
        "!pip install tensorflow-io-nightly[tensorflow-gpu]\n",
        "!apt install gdal-bin python-gdal python3-gdal ##base software for rasterio\n",
        "!pip install rasterio ##raster image handling\n"
      ],
      "metadata": {
        "id": "VUD2WbEzP6Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF3BoqYgPiCa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import datetime\n",
        "import re\n",
        "import rasterio as rio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "from natsort import natsorted, index_natsorted  ##natural sorting of strings\n",
        "from rasterio.plot import show\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are processing only ONE image for computational efficiency and storage issues"
      ],
      "metadata": {
        "id": "PSAxT2ZXA6ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##specify which image to choose (out of two generated)\n",
        "choose_ind = 0\n",
        "\n",
        "##Load Data\n",
        "\n",
        "##creating directory strings\n",
        "data_dir = os.getcwd() + \"/Data\"\n",
        "sen1_dir = data_dir + \"/s1_filled\" ##sen1 data for training\n",
        "sen2_dir = data_dir + \"/s2_reproject\" ##reading in the sentinel_2 images for testing\n",
        "numpy_masks_dir = data_dir + \"/numpy_cloud_masks\" \n",
        "\n",
        "##List image names for sentinel 1 and 2 (NOT full path) that we select\n",
        "sen1_images = [f for f in os.listdir(sen1_dir) if isfile(join(sen1_dir, f))]\n",
        "sen2_images = [f for f in os.listdir(sen2_dir) if isfile(join(sen2_dir, f))]\n",
        "\n",
        "\n",
        "##List file names for numpy masks in the chosen image directory (choose_ind)\n",
        "cloud_mask_dirs = [join(numpy_masks_dir,f) for f in natsorted(os.listdir(numpy_masks_dir))][choose_ind]\n",
        "cloud_mask_f = [f for f in os.listdir(cloud_mask_dirs) if isfile(join(cloud_mask_dirs, f))]\n",
        "\n",
        "##order file names according to ao1_{number} and pick the chosen image\n",
        "sen1_number = [re.search(r'(?<=_)[0-9]+', i).group() for i in sen1_images] ##gets ao1 number for sen1\n",
        "sen1_images = [sen1_images[i] for i in index_natsorted(sen1_number)][choose_ind] ##sorts according to sorted sen1_number and chooses selected\n",
        "\n",
        "sen2_number = [re.search(r'(?<=_)[0-9]+', i).group() for i in sen2_images] ##gets ao1 number for sen2\n",
        "sen2_images = [sen2_images[i] for i in index_natsorted(sen2_number)][choose_ind] ##sorts according to sorted sen2_number and chooses selected\n",
        "\n",
        "##read raster objects\n",
        "sen1_datasets = rio.open(join(sen1_dir,sen1_images)) ## read sen1 into a list \n",
        "sen2_datasets = rio.open(join(sen2_dir,sen2_images))## read sen2 into a list \n",
        "\n",
        "##Read in numpy cloud masks (array to tell us whether a pixel is part of a cloud or not)\n",
        "##(0 if no cloud on the pixel and 1 if cloud is on the pixel)\n",
        "cloud_mask_arrays = [np.load(join(cloud_mask_dirs,f), allow_pickle=True) for f in cloud_mask_f]"
      ],
      "metadata": {
        "id": "2fJ8ol9GPusn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define helper functions to convert raster objects to tensors"
      ],
      "metadata": {
        "id": "eFHhGF-5r3qT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##write function to convert raster objects to arrays and arrange so that bands are the third dimension\n",
        "def raster_to_array(raster, band_order=None):\n",
        "  \"\"\"\n",
        "  This function will convert a raster object into an array and arrange the array so that the bands are the third dimension.\n",
        "  It also allows a user to specify which bands to read and the order to read them in\n",
        "\n",
        "  Input:\n",
        "  raster: raster object\n",
        "  band_order: list of bands to extract and the order to extract in\n",
        "\n",
        "  Output:\n",
        "  array: numpy array with dimensions: (height (x), width (y), channel)\n",
        "  \"\"\"\n",
        "\n",
        "  ##If band_order is not supplied, just read the full raster\n",
        "  if band_order is None:\n",
        "    array = raster.read()\n",
        "  \n",
        "  ##If band_order is supplied, check to make sure it is a list and if it is, read the bands in this order\n",
        "  else:\n",
        "    \n",
        "    if not isinstance(band_order, list):\n",
        "      raise ValueError(\"band_order must be a list of numbers\")\n",
        "\n",
        "    array = raster.read(band_order)\n",
        "    \n",
        "  ##place the channel dimension as the last dimension\n",
        "  array = np.transpose(array, (1,2,0))\n",
        "\n",
        "  return array\n"
      ],
      "metadata": {
        "id": "O5uHwPMVgYU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##turn all rasters into arrays (sen2 linear predicted is already an array in the correct order)\n",
        "sen2_band_order = [3,2,1,4] ##3 is Red, 2 is Green, 1 is Blue, 4 is NIR\n",
        "sen1_arrays = raster_to_array(sen1_datasets)\n",
        "sen2_arrays = raster_to_array(sen2_datasets, band_order = sen2_band_order) ##Places bands in order R,G,B,NIR"
      ],
      "metadata": {
        "id": "TB1Dp6JErVMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##get max values for normalization\n",
        "sen1_max_vals = np.max(sen1_arrays[:,:,:2]) ##Dont include VV/VH in the normalization\n",
        "sen2_max_vals = np.max(sen2_arrays)\n",
        "\n",
        "print(f'Max Values for Sentinel-1 Arrays: {sen1_max_vals}')\n",
        "print(f'Max Values for Sentinel-2 Arrays: {sen2_max_vals}')"
      ],
      "metadata": {
        "id": "wXcy9GwE2KiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to split images into 256x256 tiles and select training and test sets. We will take all tiles without a cloud as a training set and all tiles with a cloud as the test set."
      ],
      "metadata": {
        "id": "yDcLJGlVRjWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Create raster tiles with sliding window\n",
        "##Code adapted from:\n",
        "##https://towardsdatascience.com/efficiently-splitting-an-image-into-tiles-in-python-using-numpy-d1bf0dd7b6f7\n",
        "\n",
        "##https://stackoverflow.com/questions/9979800/efficiently-reshaping-reordering-numpy-array-to-properly-ordered-tiles-image\n",
        "\n",
        "##Define function that uses np.reshape to create tiles\n",
        "def reshape_tiling(image: np.ndarray, tile_edge_size: int):\n",
        "  \"\"\"\n",
        "  This function takes an image and tiles it into tiles of size tile_edge_size x tile_edge_size\n",
        "  The input image width and height must be multiples of tile_edge_size for this to work.\n",
        "\n",
        "  Input:\n",
        "  image: a numpy array with image pixel intensities\n",
        "  tile_edge_size: Integer for width/height of tile (in pixels)\n",
        "\n",
        "  Output:\n",
        "  tiled_array: array that has been reshaped into tiles of size tile_edge_size\n",
        "  \n",
        "  \"\"\"\n",
        "  ##Extract image dimensions\n",
        "  img_height, img_width, channels = image.shape\n",
        "\n",
        "  ##Create tiled array\n",
        "  tile_height = tile_edge_size\n",
        "  tile_width = tile_edge_size\n",
        "  tiled_array = image.reshape(img_height // tile_height, ##how many tiles for the height\n",
        "                              tile_height, ##size of tile height\n",
        "                              img_width // tile_width, ##how many tiles for width\n",
        "                              tile_width, ##size of tile width\n",
        "                              channels) ##number of channels\n",
        "  tiled_array = tiled_array.swapaxes(1, 2) ##swaps axis to get in order (height, width, tile_height, tile_width, channels)\n",
        "  return tiled_array\n",
        "\n"
      ],
      "metadata": {
        "id": "puSUEeKARt_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Create a tiled array for each image (both sentinel-1 and sentinel2)\n",
        "tile_edge_size = 256\n",
        "\n",
        "##Sentinel-1 tile generation\n",
        "sen1_tiled = reshape_tiling(np.array(sen1_arrays), tile_edge_size) ##get the tiled array\n",
        "##Sentinel-2 tile generation\n",
        "sen2_tiled = reshape_tiling(np.array(sen2_arrays), tile_edge_size) ##get the tiled array"
      ],
      "metadata": {
        "id": "soVGkLNR5n8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show untiled image and tiled image for one sen2 image (to show clouds)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Full Image {choose_ind + 1}\")\n",
        "plt.imshow(sen2_arrays[:,:,0], cmap = \"pink\")\n",
        "plt.title(\"Sentinel-2: Red Channel\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Tiled Image {choose_ind + 1}\")\n",
        "##Loop over both tile dimensions (number of height tiles, number of width tiles) to plot all\n",
        "figure, ax = plt.subplots(nrows = sen2_tiled.shape[0], ncols = sen2_tiled.shape[1], figsize = (20,20))\n",
        "for i in range(0, sen2_tiled.shape[0]):\n",
        "  for j in range(0, sen2_tiled.shape[1]):\n",
        "\n",
        "    ax[i,j].imshow(sen2_tiled[i,j,:,:,0], cmap = \"pink\") ##Plot the tile and the first (Red channel)\n",
        "\n",
        "    ##Remove ticks\n",
        "    ax[i,j].set_xticks([])\n",
        "    ax[i,j].set_yticks([])\n",
        "    # figure.title(f\"Sentinel-2 Tiles: Red Channel\")\n",
        "\n",
        "figure.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AcPy3064ll1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##get tiled arrays for cloud masks (10 Random images)\n",
        "cloud_mask_tiled = [None] * len(cloud_mask_arrays) ##initialize cloud mask tile list\n",
        "\n",
        "for i in range(0, len(cloud_mask_arrays)):\n",
        "  reshaped_mask = np.reshape(cloud_mask_arrays[i], newshape = (cloud_mask_arrays[i].shape[0], cloud_mask_arrays[i].shape[1], 1)) ##3D with x,y, z=1\n",
        "  cloud_mask_tiled[i] = reshape_tiling(reshaped_mask, tile_edge_size) ##reshape to 256x256 tiles"
      ],
      "metadata": {
        "id": "s_zebZP1oSRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will split each tiled image into a training and testing set. We do not want to include any tiles with a cloud in the training set because these are \"unknown\" data that we wish to predict. As such, we need to identify whether a cloud is present in each tile depending on the cloud masks that were loaded data the beginning of this file. We will define some functions to make this process easier"
      ],
      "metadata": {
        "id": "R87mYgmM-7j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##define a helper function to check if a cloud is present in a tiled image\n",
        "def check_tiles(cloud_mask_tile_array):\n",
        "  \"\"\"\n",
        "  This function takes a tiled cloud mask image and checks to see if any clouds are present in each tile\n",
        "\n",
        "  Input:\n",
        "  cloud_mask_tile_array: tiled cloud mask image array\n",
        "\n",
        "  Output:\n",
        "  cloud_check: Array for each tile with a value of 1 if there is a cloud in the tile and 0 if there is not\n",
        "  \"\"\"\n",
        "\n",
        "  tile_rows, tile_cols = cloud_mask_tile_array.shape[0], cloud_mask_tile_array.shape[1] ##get number of tile rows and cols\n",
        "\n",
        "  ##Initialize cloud checking array with a zeros array\n",
        "  cloud_check = np.zeros(shape = (tile_rows, tile_cols))\n",
        "  ##Loop over tile rows and columns to check if there is a cloud in each tile\n",
        "  ##If there is a cloud, change that index from 0 to 1\n",
        "  for i in range(0, tile_rows):\n",
        "\n",
        "    for j in range(0, tile_cols):\n",
        "      ##if there are ANY cloud pixels (array.sum > 0), that tile has a cloud\n",
        "      ##image dimensions are (tile row, tile col, tile width, tile height, 1)\n",
        "      ##It only has one channel, so the channel's index is 0\n",
        "      if cloud_mask_tile_array[i,j,:,:,0].sum() > 0: \n",
        "        cloud_check[i,j] = 1 ##set to 1 if there is a cloud\n",
        "\n",
        "  return(cloud_check)\n",
        "\n",
        "\n",
        "\n",
        "##Write a function that will get the indices required to split a tiled dataframe into train and test data for each image\n",
        "##Train is the non-cloud tiles and test is the cloud tiles\n",
        "def get_train_test_indices(cloud_check_array):\n",
        "  \"\"\"\n",
        "  This function takes a boolean cloud check array (whether a cloud is in a tile) and gets the\n",
        "  indices of training set that does NOT include cloudy tiles.\n",
        "\n",
        "  The test set is defined as the tiles WITH clouds\n",
        "\n",
        "  This method for splitting maximizes the amount of training data that can be used in the deep learning model\n",
        "\n",
        "  Input: \n",
        "  cloud_check_array: Array for each tile with a value of 1 if there is a cloud in the tile and 0 if there is not\n",
        "  \n",
        "  Output: \n",
        "  train_ind: Indices of tiles used for training (no cloud tiles present)\n",
        "  test_ind: Indices of tiles used for testing (cloud tiles present)\n",
        "  total_percentage_selected: total percentage of data used for training to yield a \"train_perc\" (which does not include cloud tiles)\n",
        "  \"\"\"\n",
        "\n",
        "  ##get indices where NO clouds are present\n",
        "  no_cloud_index = np.where(cloud_check_array == 0) ##this returns a tuple with dimensions (0: 2, 1: number of no cloud pixels)\n",
        "\n",
        "  ##Calculate the percentage of tiles not covered by clouds for each image\n",
        "  n_tiles = cloud_check_array.size ##total number of tiles\n",
        "  n_cloud_tiles = cloud_check_array.sum() ##number of cloud tiles\n",
        "  n_no_clouds = n_tiles-n_cloud_tiles ##count of tiles with no clouds\n",
        "  no_cloud_perc = n_no_clouds/n_tiles ##percentage of tiles with no clouds\n",
        "\n",
        "  ##Identify training Indices\n",
        "  train_ind = no_cloud_index ##indices of original tiled image with no clouds\n",
        "\n",
        "  ##Identify testing Indices (portion of no_cloud index without clouds)\n",
        "  ##We will do this by creating a boolean masks for test data so we can get the actual indices using np.where\n",
        "  test_ind = np.where(cloud_check_array == 1)\n",
        "\n",
        "\n",
        "  ##return train indices, test indices, and no cloud percent (true training percentage)\n",
        "  return train_ind, test_ind, no_cloud_perc\n",
        "\n",
        "##Define function that will separate a tiled image into train and test depending on a defined training percentage\n",
        "##This function does NOT include tiles with clouds in the training dataset, so the \"train_perc\"\n",
        "##Is actually defined by n_train/number_tiles_without_clouds. The test set will have the remaining tiles without clouds\n",
        "##AND the tiles with clouds. It has an option to return the \"true\" training percentage for visualization purposes\n",
        "\n",
        "##This funciton saves the tiled image to a defined output path rather than outputing the object\n",
        "\n",
        "\n",
        "def train_test_split_image(tiled_image, cloud_mask_tile_array, train_output_dir, test_output_dir,\n",
        "                           train_image_identifier, test_image_identifier, return_total_train_perc= False):\n",
        "  \"\"\"\n",
        "  This function takes a tiled image and a boolean mask for whether a cloud is in a tile,\n",
        "  and selects the indices of a training and test set. The training set is the set of tiles with no clouds\n",
        "  and the test set is the set of tiles with a cloud\n",
        "\n",
        "  It has an option to return the \"true\" training percentage for visualization purposes.\n",
        "\n",
        "  Input:\n",
        "  tiled_image: An image separated into tiles\n",
        "  cloud_mask_tile_array: A boolean array (1 for if a pixel is a cloud and 0 for if a pixel is not a cloud) separated into tiles\n",
        "  train_output_dir: Output directory for the separated training tiled arrays\n",
        "  test_output_dir: Output directory for the separated test tiled arrays\n",
        "  train_image_identifier: String name for image (no spaces) that can be used to identify the training array/image it came from \n",
        "  test_image_identifier: String name for image (no spaces) that can be used to identify the test array/image it came from \n",
        "  return_true_train_perc: Boolean for whether to return the total percentage of data used for training (not just tiles with no clouds)\n",
        "\n",
        "  Output:\n",
        "  Saves tiled numpy arrays to destination_path\n",
        "  total_percentage_selected(Optional): the total percentage of data used for training (percent calculated including cloudy tiles)\n",
        "  \"\"\"\n",
        "\n",
        "  ##First step is to check each tile to see if clouds are present and return\n",
        "  ##a boolean array for each tile where 1 = cloud and 0 = no cloud\n",
        "  cloud_check_array = check_tiles(cloud_mask_tile_array)\n",
        "\n",
        "  ##Next we get the indices of the training, test, and verification/cloud sets that yield a training percentage of train_perc\n",
        "  ##Again train_perc is the percent out of the NON-cloudy tiles\n",
        "  ##We also output the total percentage of data used for training INCLUDING cloudy tiles\n",
        "  train_index, test_index, total_percentage_selected = get_train_test_indices(cloud_check_array)\n",
        "  train_index = np.array(train_index).reshape(2,-1) ##turn to array for easy indexing\n",
        "  test_index = np.array(test_index).reshape(2,-1) ##turn to array for easy indexing\n",
        "\n",
        "\n",
        "  ##separate the train tiles into separate images and save\n",
        "  n_train = train_index.shape[1] ##size of training set\n",
        "  for i in range(n_train):\n",
        "    row_ind, col_ind = train_index[:,i] ##get tile row and column indices\n",
        "    destination_path = join(train_output_dir, f\"{train_image_identifier}_({row_ind},{col_ind}).npy\") ##unique destination path for tile\n",
        "    tile = np.array(tiled_image[row_ind, col_ind, :, :, :]) ##select the tile of interest in the loop\n",
        "    np.save(destination_path, tile) ##save the tile of interest\n",
        "\n",
        "  ##separate the test tiles into separate images and save\n",
        "  n_test = test_index.shape[1] ##size of training set\n",
        "  for i in range(n_test):\n",
        "    row_ind, col_ind = test_index[:,i] ##get tile row and column indices\n",
        "    destination_path = join(test_output_dir, f\"{test_image_identifier}_({row_ind},{col_ind}).npy\") ##unique destination path for tile\n",
        "    tile = np.array(tiled_image[row_ind, col_ind, :, :, :]) ##select the tile of interest in the loop\n",
        "    np.save(destination_path, tile) ##save the tile of interest\n",
        "\n",
        "  ##If the total percentage of data used for training is desired, return it\n",
        "  if return_total_train_perc == True:\n",
        "    return(total_percentage_selected)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V0KWuYgV_IKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a tensorflow pipeline, it is easier to manage if the input and output image are located in the same file. As such, we will stack sentinel-1 tiles on top of sentinel-2 files, so the output image will have 7 bands, 3 for sentinel one (dims 0,1,2) and 4 for sentinel-2 (dims 3,4,5,6)."
      ],
      "metadata": {
        "id": "MwaBIs6exhO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##define a function to stack sentinel-1 and sentinel-2 tiles\n",
        "def stack_tiled_arrays(sentinel_1_tiled, sentinel_2_tiled):\n",
        "  \"\"\"\n",
        "  This function stacks sentinel-1 tiled arrays on tope of sentinel-2 tiled arrays, so the \n",
        "  final tiled array has 7 stacked arrays. \n",
        "  The dimensions are: (tile_row, tile_col, tile_width, tile_height, channel)\n",
        "  Sentinel-1 is in channels 0,1,2 and sentinel-2 is in channels 3,4,5\n",
        "\n",
        "  Input:\n",
        "  sentinel_1_tiled: sentinel-1 tiled array\n",
        "  sentinel_2_tiled: sentinel-2 tiled array\n",
        "\n",
        "  Output:\n",
        "  stacked_tiled_array: array of dim (tile_row, tole_col, tile_width, tile_height, channel)\n",
        "                       with the first three channels as sentinel-2 and last four as sentinel-2\n",
        "  \"\"\"\n",
        "\n",
        "  ##stacking sentinel-1 images on top of sentinel-2 images for tensorflow pipeline management\n",
        "  sen1_channels = sentinel_1_tiled.shape[4] ##total number of channels in sen1\n",
        "  sen2_channels = sentinel_2_tiled.shape[4] ##total number of channels in sen2\n",
        "  channel_axis = 4 ##the axis for channels is dimension 4\n",
        "  sen1_list = np.split(sentinel_1_tiled, sen1_channels, axis = channel_axis) ##split sen1 arrays\n",
        "  sen2_list = np.split(sentinel_2_tiled, sen2_channels, axis = channel_axis) ##split sen2 arrays\n",
        "  tiled_list = sen1_list + sen2_list ## combine the lists\n",
        "  stacked_tiled_array = np.stack(tuple(tiled_list), axis = channel_axis) ##stack the tiles\n",
        "  stacked_tiled_array = stacked_tiled_array[:,:,:,:,:,0] ##drop the last unused dimension which is created during the np.stack\n",
        "\n",
        "  return(stacked_tiled_array)\n"
      ],
      "metadata": {
        "id": "jsOg9ienxO7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking sentinel-1 and seninel-2 as input for the train-test split"
      ],
      "metadata": {
        "id": "uit7FmmmHXsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##stack tiles for next part\n",
        "stacked_tiles = stack_tiled_arrays(sen1_tiled, sen2_tiled)"
      ],
      "metadata": {
        "id": "vJl83FcWHXFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are NO LONGER creating a separate testing set. The cloud data will be the testing set itself.\n",
        "\n",
        "Need to create different training sets for each cloud image"
      ],
      "metadata": {
        "id": "RTZakiZEN-r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Separate Tiled images into train and test sets for both sentinel-1 and sentinel-2\n",
        "##We will stack sen-1 and sen-2 in the same array and save for ease of use with tensorflow pipeline\n",
        "\n",
        "##Get the image identifier to use for the sen1/sen2_images aoi_{number}_cloud_{number}\n",
        "identifiers = [f\"{re.search(r'aoi_[0-9]+',sen1_images).group()}_cloud_{i+1}\" for i in list(range(len(cloud_mask_tiled)))]  ##gets s1_aoi_[1-10] for the selected\n",
        "\n",
        "##Loop through the total number of random clouds and generate the separates train/test sets for each\n",
        "##Also generate the total train percentages for each random cloud\n",
        "total_train_percentages = [None] * len(cloud_mask_tiled) ##Initialize percentage list\n",
        "\n",
        "##create overall directories to house training/testing data\n",
        "training_dir = join(data_dir, \"training_data\") #training dir\n",
        "testing_dir = join(data_dir, \"testing_data\") ##testing dir\n",
        "\n",
        "##set seed for consistent train/test images\n",
        "seed = 92\n",
        "np.random.seed(seed)\n",
        "\n",
        "if not os.path.exists(training_dir):\n",
        "    os.mkdir(training_dir)\n",
        "    print(\"Directory created!\")\n",
        "\n",
        "if not os.path.exists(testing_dir):\n",
        "    os.mkdir(testing_dir)\n",
        "    print(\"Directory created!\")\n",
        "\n",
        "\n",
        "##Loop through the random clouds\n",
        "for k in range(len(cloud_mask_tiled)):\n",
        "\n",
        "  ##Make output directories depending on the image for training and testing\n",
        "\n",
        "  ##training: format is aoi_[choose_ind]_training since images are numbered from 1-10\n",
        "  train_output_dir = join(training_dir,f\"aoi_{choose_ind + 1}_cloud{k+1}_training\")\n",
        "  if not os.path.exists(train_output_dir):\n",
        "    os.mkdir(train_output_dir)\n",
        "    print(\"Directory created!\")\n",
        "\n",
        "  #testing: format is aoi_[k+1]_testing since images are numbered from 1-10\n",
        "  test_output_dir = join(testing_dir,f\"aoi_{choose_ind + 1}_cloud{k+1}_testing\") \n",
        "  if not os.path.exists(test_output_dir):\n",
        "    os.mkdir(test_output_dir)\n",
        "    print(\"Directory created!\")\n",
        "\n",
        "\n",
        "  ##separate the sen-1/sen-2 stacked array into train/test/verification, save, and return total_train_percentage\n",
        "  ##using the sentinel-2 linear predicted as the sentinel-2 image here\n",
        "  print(f\"Saving Data for Cloud {k+1}\")\n",
        "\n",
        "  total_train_percentages[k] = train_test_split_image(tiled_image = stacked_tiles, \n",
        "                                                      cloud_mask_tile_array = cloud_mask_tiled[k],\n",
        "                                                      train_output_dir = train_output_dir, \n",
        "                                                      test_output_dir = test_output_dir,\n",
        "                                                      train_image_identifier = identifiers[k], \n",
        "                                                      test_image_identifier = identifiers[k], \n",
        "                                                      return_total_train_perc= True)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "cY-suWxsSVzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the actual percentages used for train test"
      ],
      "metadata": {
        "id": "T5OOEJJ6fFgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Get \"training\" percentages. This is the percentage of whole data used to train \n",
        "##such that 90% of the uncloudy data is used to train\n",
        "bar_x = list(range(1, len(sen1_tiled) + 1)) ##Image numbers\n",
        "total_percentage_data = pd.DataFrame({\"Random Cloud Image\": bar_x, \"Percentage of Tiles Selected for Training\": np.round(total_train_percentages, 2)}) ##\n",
        "ax = sns.barplot(x='Random Cloud Image', y='Percentage of Tiles Selected for Training', data = total_percentage_data)\n",
        "ax.bar_label(ax.containers[0])\n"
      ],
      "metadata": {
        "id": "rf9xntdVpus3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code was used for a previous version. I kept it because it is useful, but it is not relevant for this analysis"
      ],
      "metadata": {
        "id": "7dTXledX1MuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ##define a helper function to check if a cloud is present in a tiled image\n",
        "# def check_tiles(cloud_mask_tile_array):\n",
        "#   \"\"\"\n",
        "#   This function takes a tiled cloud mask image and checks to see if any clouds are present in each tile\n",
        "\n",
        "#   Input:\n",
        "#   cloud_mask_tile_array: tiled cloud mask image array\n",
        "\n",
        "#   Output:\n",
        "#   cloud_check: Array for each tile with a value of 1 if there is a cloud in the tile and 0 if there is not\n",
        "#   \"\"\"\n",
        "\n",
        "#   tile_rows, tile_cols = cloud_mask_tile_array.shape[0], cloud_mask_tile_array.shape[1] ##get number of tile rows and cols\n",
        "\n",
        "#   ##Initialize cloud checking array with a zeros array\n",
        "#   cloud_check = np.zeros(shape = (tile_rows, tile_cols))\n",
        "#   ##Loop over tile rows and columns to check if there is a cloud in each tile\n",
        "#   ##If there is a cloud, change that index from 0 to 1\n",
        "#   for i in range(0, tile_rows):\n",
        "\n",
        "#     for j in range(0, tile_cols):\n",
        "#       ##if there are ANY cloud pixels (array.sum > 0), that tile has a cloud\n",
        "#       ##image dimensions are (tile row, tile col, tile width, tile height, 1)\n",
        "#       ##It only has one channel, so the channel's index is 0\n",
        "#       if cloud_mask_tile_array[i,j,:,:,0].sum() > 0: \n",
        "#         cloud_check[i,j] = 1 ##set to 1 if there is a cloud\n",
        "\n",
        "#   return(cloud_check)\n",
        "\n",
        "\n",
        "\n",
        "# ##Write a function that will get the indices required to split a tiled dataframe into train and test data for each image\n",
        "# def get_train_test_indices(cloud_check_array, train_perc):\n",
        "#   \"\"\"\n",
        "#   This function takes a boolean cloud check array (whether a cloud is in a tile) and gets the\n",
        "#   indices of a random training set and test set that do NOT include cloudy tiles.\n",
        "#   These are based on the defined train_perc where train_perc is the percent of tiles to take for training\n",
        "#   FROM the NON-cloudy tiles.\n",
        "\n",
        "#   It also gets the indices for the verification set (the set WITH clouds) to select these tiles for verification\n",
        "\n",
        "#   Input: \n",
        "#   cloud_check_array: Array for each tile with a value of 1 if there is a cloud in the tile and 0 if there is not\n",
        "#   train_perc: percent of tiles to take for training\n",
        "  \n",
        "#   Output: \n",
        "#   train_ind: Indices of tiles used for training (no cloud tiles present)\n",
        "#   test_ind: Indices of tiles used for testing (cloud tiles present)\n",
        "#   total_percentage_selected: total percentage of data used for training to yield a \"train_perc\" (which does not include cloud tiles)\n",
        "#   \"\"\"\n",
        "\n",
        "#   ##get indices where NO clouds are present\n",
        "#   no_cloud_index = np.where(cloud_check_array == 0) ##this returns a tuple with dimensions (0: 2, 1: number of no cloud pixels)\n",
        "#   no_cloud_index_array = np.asarray(no_cloud_index).reshape(2,-1) ##reshape to an array for easy manipulation\n",
        "\n",
        "#   ##Calculate the percentage of tiles not covered by clouds for each image\n",
        "#   ##the no_cloud_index dimensions are (0: 2, 1: count of tiles with no clouds)\n",
        "#   ##so to get the count of tiles with no clouds we do no_cloud_index.shape[1]\n",
        "#   ##To get total number of tiles, we can just do cloud_check_array.size\n",
        "#   n_no_clouds = no_cloud_index_array.shape[1] ##count of tiles with no clouds\n",
        "#   n_tiles = cloud_check_array.size ##total number of tiles\n",
        "#   no_cloud_perc = n_no_clouds/n_tiles ##percentage of tiles with no clouds\n",
        "\n",
        "#   ##Calculate the size of the training data required to yield a *train_perc* where the\n",
        "#   ##training percentage is defined as train_perc = n_train/n_no_clouds\n",
        "#   n_train = np.floor(n_no_clouds * train_perc).astype(int) ##number to select for training to yield a \"train_perc\" that doesn't include cloud tiles\n",
        "#   total_percentage_selected = train_perc * no_cloud_perc ##total percentage of data selected including cloud tiles\n",
        "\n",
        "#   ##Identify training Indices\n",
        "#   ##We first randomly select n_train integers from 0 to total number of no clouds\n",
        "#   ##Then using these integers as indices, we select the indices of tiles (with no clouds) to use for training\n",
        "#   no_cloud_select = np.sort(np.random.choice(range(0, n_no_clouds), n_train, replace = False)) ##random integers used to select training indices\n",
        "#   train_ind = tuple(no_cloud_index_array[:,no_cloud_select]) ##indices from original tiled image to choose for training (set to tuple because this is required for array indexing)\n",
        "\n",
        "#   ##Identify testing Indices (portion of no_cloud index without clouds)\n",
        "#   ##We will do this by creating a boolean masks for test data so we can get the actual indices using np.where\n",
        "#   test_mask = np.ones(shape = cloud_check_array.shape) ##create ones array same shape as tiled image\n",
        "#   test_mask[train_ind] = 0 ##set the train indices to zero (Need to convert to tuple for it to work)\n",
        "#   test_ind = np.where((test_mask == 1) * (cloud_check_array == 0) == True) ##get indices for test\n",
        "\n",
        "#   ##Identify cloud/verification indices for model verification\n",
        "#   verification_indices = np.where(cloud_check_array == 1)\n",
        "\n",
        "\n",
        "#   return train_ind, test_ind, verification_indices, total_percentage_selected\n",
        "\n",
        "# ##Define function that will separate a tiled image into train and test depending on a defined training percentage\n",
        "# ##This function does NOT include tiles with clouds in the training dataset, so the \"train_perc\"\n",
        "# ##Is actually defined by n_train/number_tiles_without_clouds. The test set will have the remaining tiles without clouds\n",
        "# ##AND the tiles with clouds. It has an option to return the \"true\" training percentage for visualization purposes\n",
        "\n",
        "# ##This funciton saves the tiled image to a defined output path rather than outputing the object\n",
        "\n",
        "\n",
        "# def train_test_split_image(tiled_image, cloud_mask_tile_array, train_perc, train_output_dir, test_output_dir, verification_output_dir,\n",
        "#                            train_image_identifier, test_image_identifier, verification_image_identifier, return_total_train_perc= False):\n",
        "#   \"\"\"\n",
        "#   This function takes a tiled image and a boolean mask for whether a cloud is in a tile,\n",
        "#   and selects the indices of a random training set, test set, and cloud index (verification). This selection is based\n",
        "#   on whether a cloud is present in a tile (cloud_check_array) and and the defined train_perc. \n",
        "#   The defined train_perc is actually n_train/number_tiles_without_clouds.\n",
        "\n",
        "#   The train set is the random training set without clouds,\n",
        "#   the test set is the remaining tiles without clouds, and \n",
        "#   the cloud/verification set is all tiles with a cloud.\n",
        "\n",
        "#   It has an option to return the \"true\" training percentage for visualization purposes.\n",
        "\n",
        "#   Input:\n",
        "#   tiled_image: An image separated into tiles\n",
        "#   cloud_mask_tile_array: A boolean array (1 for if a pixel is a cloud and 0 for if a pixel is not a cloud) separated into tiles\n",
        "#   train_perc: The desired percentage of NON-cloud images to be included in the training set (ie n_train/number_tiles_without_clouds)\n",
        "#   train_output_dir: Output directory for the separated training tiled arrays\n",
        "#   test_output_dir: Output directory for the separated test tiled arrays\n",
        "#   verification_output_dir: Output directory for the separated verification (cloud) tiled arrays\n",
        "#   train_image_identifier: String name for image (no spaces) that can be used to identify the training array/image it came from \n",
        "#   test_image_identifier: String name for image (no spaces) that can be used to identify the test array/image it came from \n",
        "#   verification_image_identifier: String name for image (no spaces) that can be used to identify the verification (cloudy) array/image it came from \n",
        "#   return_true_train_perc: Boolean for whether to return the total percentage of data used for training (not just tiles with no clouds)\n",
        "\n",
        "#   Output:\n",
        "#   Saves tiled numpy arrays to destination_path\n",
        "#   total_percentage_selected(Optional): the total percentage of data used for training (percent calculated including cloudy tiles)\n",
        "#   \"\"\"\n",
        "\n",
        "#   ##First step is to check each tile to see if clouds are present and return\n",
        "#   ##a boolean array for each tile where 1 = cloud and 0 = no cloud\n",
        "#   cloud_check_array = check_tiles(cloud_mask_tile_array)\n",
        "\n",
        "#   ##Next we get the indices of the training, test, and verification/cloud sets that yield a training percentage of train_perc\n",
        "#   ##Again train_perc is the percent out of the NON-cloudy tiles\n",
        "#   ##We also output the total percentage of data used for training INCLUDING cloudy tiles\n",
        "#   train_index, test_index, verification_index, total_percentage_selected = get_train_test_indices(cloud_check_array, train_perc)\n",
        "#   train_index = np.array(train_index).reshape(2,-1) ##turn to array for easy indexing\n",
        "#   test_index = np.array(test_index).reshape(2,-1) ##turn to array for easy indexing\n",
        "#   verification_index = np.array(verification_index).reshape(2,-1) ##turn to array for easy indexing\n",
        "\n",
        "\n",
        "#   ##separate the train tiles into separate images and save\n",
        "#   n_train = train_index.shape[1] ##size of training set\n",
        "#   for i in range(0, n_train):\n",
        "#     row_ind, col_ind = train_index[:,i] ##get tile row and column indices\n",
        "#     destination_path = join(train_output_dir, f\"{train_image_identifier}_({row_ind},{col_ind}).npy\") ##unique destination path for tile\n",
        "#     tile = np.array(tiled_image[row_ind, col_ind, :, :, :]) ##select the tile of interest in the loop\n",
        "#     np.save(destination_path, tile) ##save the tile of interest\n",
        "\n",
        "#   ##separate the test tiles into separate images and save\n",
        "#   n_test = test_index.shape[1] ##size of training set\n",
        "#   for i in range(0, n_test):\n",
        "#     row_ind, col_ind = test_index[:,i] ##get tile row and column indices\n",
        "#     destination_path = join(test_output_dir, f\"{test_image_identifier}_({row_ind},{col_ind}).npy\") ##unique destination path for tile\n",
        "#     tile = np.array(tiled_image[row_ind, col_ind, :, :, :]) ##select the tile of interest in the loop\n",
        "#     np.save(destination_path, tile) ##save the tile of interest\n",
        "\n",
        "#   ##separate the verification/cloud tiles into separate images and save\n",
        "#   n_cloud = verification_index.shape[1] ##size of training set\n",
        "#   for i in range(0, n_cloud):\n",
        "#     row_ind, col_ind = verification_index[:,i] ##get tile row and column indices\n",
        "#     destination_path = join(verification_output_dir, f\"{verification_image_identifier}_({row_ind},{col_ind}).npy\") ##unique destination path for tile\n",
        "#     tile = np.array(tiled_image[row_ind, col_ind, :, :, :]) ##select the tile of interest in the loop\n",
        "#     np.save(destination_path, tile) ##save the tile of interest\n",
        "\n",
        "#   ##If the total percentage of data used for training is desired, return it\n",
        "#   if return_total_train_perc == True:\n",
        "#     return(total_percentage_selected)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yEARK0MwhT7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Helper function to convert sen1 and sen2 rasters to tensors to prevent saving multiple intermediate arrays\n",
        "# def raster_to_tensor(raster, band_order = None):\n",
        "#   \"\"\"\n",
        "#   This function will convert sentinel-1 and sentinel-2 raster objects to tensors by first converting\n",
        "#   to an array and then converting to a tensor. It also allows specifying the band order, \n",
        "#   which we will use to ensure sentinel 2 is in the order Red, Green, Blue, NIR.\n",
        "\n",
        "#   Note that the intermediate conversion from raster to array changes the dimension\n",
        "#   order from (channel, height-x, width-y) to (height-x, width-y, channel)\n",
        "\n",
        "#   Input:\n",
        "#   raster: raster object to convert to tensor\n",
        "#   band_order: list of bands to extract and order to extract them in\n",
        "\n",
        "#   Output:\n",
        "#   tensor: raster converted to tensor\n",
        "#   \"\"\"\n",
        "\n",
        "#   ##For both sentinel-1 and sentinel-2 we convert to an array\n",
        "#   array = raster_to_array(raster, band_order) ##convert to array\n",
        "\n",
        "#   ##For both convert from array to tensor\n",
        "#   tensor = tf.convert_to_tensor(array, dtype = None, dtype_hint = None, name = None)\n",
        "\n",
        "#   return tensor"
      ],
      "metadata": {
        "id": "4MNl-KsO9fQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}